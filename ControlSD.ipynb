{"cells":[{"cell_type":"code","source":["!git clone https://github.com/huggingface/diffusers\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cZUJGJXXgox","executionInfo":{"status":"ok","timestamp":1719209347389,"user_tz":-330,"elapsed":450,"user":{"displayName":"chaturya ganne","userId":"10364823250779832102"}},"outputId":"2a9bd305-b09e-4c64-c46f-99b7a936cb20"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'diffusers' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["%cd diffusers\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TU0wHqdtXgwt","executionInfo":{"status":"ok","timestamp":1719209348998,"user_tz":-330,"elapsed":6,"user":{"displayName":"chaturya ganne","userId":"10364823250779832102"}},"outputId":"ead99be2-2ab3-498d-91e4-159d55bd2147"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/diffusers\n"]}]},{"cell_type":"code","source":["!pip install -e ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N8kvizEWXgzj","executionInfo":{"status":"ok","timestamp":1719209379151,"user_tz":-330,"elapsed":27346,"user":{"displayName":"chaturya ganne","userId":"10364823250779832102"}},"outputId":"51fe7bbd-77b6-4462-b469-547d86bf06b1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Obtaining file:///content/diffusers\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.30.0.dev0) (7.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.30.0.dev0) (3.15.1)\n","Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.30.0.dev0) (0.23.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.30.0.dev0) (1.25.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.30.0.dev0) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.30.0.dev0) (2.32.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.30.0.dev0) (0.4.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.30.0.dev0) (9.4.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.30.0.dev0) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.30.0.dev0) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.30.0.dev0) (6.0.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.30.0.dev0) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.30.0.dev0) (4.12.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.30.0.dev0) (3.19.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.30.0.dev0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.30.0.dev0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.30.0.dev0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.30.0.dev0) (2024.6.2)\n","Building wheels for collected packages: diffusers\n","  Building editable for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for diffusers: filename=diffusers-0.30.0.dev0-0.editable-py3-none-any.whl size=11095 sha256=c2e6b648f7b90c13a0e0b6eab0c7ea43d54afc45a3411d66a4e12c0b258217cf\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-3yz54ryq/wheels/95/c5/3b/e1b4269f8a2584de57e75f949a185b48fc4144e9a91fc9965a\n","Successfully built diffusers\n","Installing collected packages: diffusers\n","  Attempting uninstall: diffusers\n","    Found existing installation: diffusers 0.30.0.dev0\n","    Uninstalling diffusers-0.30.0.dev0:\n","      Successfully uninstalled diffusers-0.30.0.dev0\n","Successfully installed diffusers-0.30.0.dev0\n"]}]},{"cell_type":"code","source":["%cd examples\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CtaqnOwrXg2R","executionInfo":{"status":"ok","timestamp":1719209379151,"user_tz":-330,"elapsed":15,"user":{"displayName":"chaturya ganne","userId":"10364823250779832102"}},"outputId":"729e0f0c-1a24-404f-d5e9-cf1753c63b49"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/diffusers/examples\n"]}]},{"cell_type":"code","source":["%cd controlnet\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4m5x9DwxXg54","executionInfo":{"status":"ok","timestamp":1719209384810,"user_tz":-330,"elapsed":419,"user":{"displayName":"chaturya ganne","userId":"10364823250779832102"}},"outputId":"f8d84cdd-c6ba-434b-84a5-9249941284e5"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/diffusers/examples/controlnet\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x7vEwNeiXhCr","executionInfo":{"status":"ok","timestamp":1719209406958,"user_tz":-330,"elapsed":20658,"user":{"displayName":"chaturya ganne","userId":"10364823250779832102"}},"outputId":"16e7a645-63a7-41b5-b08b-0d0d817a52fd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: accelerate>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.31.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.18.0+cu121)\n","Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.41.2)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (6.2.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.15.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.20.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (2.3.0+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (0.23.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (0.4.3)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.15.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (12.5.40)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (2.32.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (4.66.4)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements.txt (line 4)) (0.2.13)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (1.64.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (3.6)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (3.0.3)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 6)) (16.1.0)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 6)) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 6)) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 6)) (2.0.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 6)) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 6)) (0.70.16)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 6)) (3.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 6)) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 6)) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 6)) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 6)) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 6)) (4.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 5)) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r requirements.txt (line 3)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r requirements.txt (line 3)) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r requirements.txt (line 3)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r requirements.txt (line 3)) (2024.6.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 5)) (2.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 6)) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 6)) (2024.1)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 5)) (3.2.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (1.3.0)\n"]}]},{"cell_type":"code","source":["!pip install accelerate\n","from accelerate.utils import write_basic_config\n","write_basic_config()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w3w45M46XhFc","executionInfo":{"status":"ok","timestamp":1719209437437,"user_tz":-330,"elapsed":30485,"user":{"displayName":"chaturya ganne","userId":"10364823250779832102"}},"outputId":"72832978-2907-4fc9-c46b-674a8172af81"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.31.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.15.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"]},{"output_type":"execute_result","data":{"text/plain":["PosixPath('/root/.cache/huggingface/accelerate/default_config.yaml')"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["\n","!wget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_1.png\n","!wget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_2.png\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83ruhgi2dzBh","executionInfo":{"status":"ok","timestamp":1719209438122,"user_tz":-330,"elapsed":704,"user":{"displayName":"chaturya ganne","userId":"10364823250779832102"}},"outputId":"04586ab2-5b7b-42db-aa01-2543b79e4963"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-06-24 06:10:35--  https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_1.png\n","Resolving huggingface.co (huggingface.co)... 18.172.134.4, 18.172.134.124, 18.172.134.88, ...\n","Connecting to huggingface.co (huggingface.co)|18.172.134.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cdn-lfs.huggingface.co/datasets/huggingface/documentation-images/fe26d74518b1ba2f566e9971cf7e1eecb018090da2c2e0c87323cb60f54a8d51?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27conditioning_image_1.png%3B+filename%3D%22conditioning_image_1.png%22%3B&response-content-type=image%2Fpng&Expires=1719468635&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxOTQ2ODYzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9kYXRhc2V0cy9odWdnaW5nZmFjZS9kb2N1bWVudGF0aW9uLWltYWdlcy9mZTI2ZDc0NTE4YjFiYTJmNTY2ZTk5NzFjZjdlMWVlY2IwMTgwOTBkYTJjMmUwYzg3MzIzY2I2MGY1NGE4ZDUxP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&Signature=ob9kfHfuKaoCoV4cx%7EhM3IG4COyqBJFXdQqR1W-q-R3KPVd9AOBXJQCQMRmBowyYXEUm0NZveS7m2padBba72i-6YjaBmSSc0mhlSXcktJcy28MnuO6Jhk0SNMSxq1tVb9Bw1rRUHAmkvxt%7E%7E2SCxkWXioGhqy2vJY0A24lrYtGEB2a7-vYTOXTVjSrG-BicqQFBmpY8N8yOrqIyZckz-R%7ErnM%7EZ60TqG48e2M2WC3qgWXWut1GairaUFyf-bHhwL8hyp3Lu57mJg5Y2SoJgsDqpVlFji7hids2OlZdJgyMJ-taHNjxwWSFAY5f33OxsAylHd1YQUbi0fI8VnMxZqQ__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n","--2024-06-24 06:10:35--  https://cdn-lfs.huggingface.co/datasets/huggingface/documentation-images/fe26d74518b1ba2f566e9971cf7e1eecb018090da2c2e0c87323cb60f54a8d51?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27conditioning_image_1.png%3B+filename%3D%22conditioning_image_1.png%22%3B&response-content-type=image%2Fpng&Expires=1719468635&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxOTQ2ODYzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9kYXRhc2V0cy9odWdnaW5nZmFjZS9kb2N1bWVudGF0aW9uLWltYWdlcy9mZTI2ZDc0NTE4YjFiYTJmNTY2ZTk5NzFjZjdlMWVlY2IwMTgwOTBkYTJjMmUwYzg3MzIzY2I2MGY1NGE4ZDUxP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&Signature=ob9kfHfuKaoCoV4cx%7EhM3IG4COyqBJFXdQqR1W-q-R3KPVd9AOBXJQCQMRmBowyYXEUm0NZveS7m2padBba72i-6YjaBmSSc0mhlSXcktJcy28MnuO6Jhk0SNMSxq1tVb9Bw1rRUHAmkvxt%7E%7E2SCxkWXioGhqy2vJY0A24lrYtGEB2a7-vYTOXTVjSrG-BicqQFBmpY8N8yOrqIyZckz-R%7ErnM%7EZ60TqG48e2M2WC3qgWXWut1GairaUFyf-bHhwL8hyp3Lu57mJg5Y2SoJgsDqpVlFji7hids2OlZdJgyMJ-taHNjxwWSFAY5f33OxsAylHd1YQUbi0fI8VnMxZqQ__&Key-Pair-Id=K3ESJI6DHPFC7\n","Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.185.94, 18.154.185.26, 18.154.185.64, ...\n","Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.185.94|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 26716 (26K) [image/png]\n","Saving to: ‘conditioning_image_1.png’\n","\n","conditioning_image_ 100%[===================>]  26.09K  --.-KB/s    in 0.01s   \n","\n","2024-06-24 06:10:35 (2.36 MB/s) - ‘conditioning_image_1.png’ saved [26716/26716]\n","\n","--2024-06-24 06:10:35--  https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_2.png\n","Resolving huggingface.co (huggingface.co)... 18.172.134.24, 18.172.134.4, 18.172.134.124, ...\n","Connecting to huggingface.co (huggingface.co)|18.172.134.24|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cdn-lfs.huggingface.co/datasets/huggingface/documentation-images/e037bbf4836b97f1034f3a16e144e5184e67058a5cc2dd4b2c966d916dfbfd1f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27conditioning_image_2.png%3B+filename%3D%22conditioning_image_2.png%22%3B&response-content-type=image%2Fpng&Expires=1719468635&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxOTQ2ODYzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9kYXRhc2V0cy9odWdnaW5nZmFjZS9kb2N1bWVudGF0aW9uLWltYWdlcy9lMDM3YmJmNDgzNmI5N2YxMDM0ZjNhMTZlMTQ0ZTUxODRlNjcwNThhNWNjMmRkNGIyYzk2NmQ5MTZkZmJmZDFmP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&Signature=bHQ0NreHamLgRvujtOpu4XSW3AawxBFRddxPM3n01p2txBTV7Bs3wPhTes1lcbPFznD78teW%7E0pjPmJFdhKqiL5BxtFBtwqfXKUDZtm9aTKpZ11%7Egzz7-IN09uDwLj%7EyiUUYdcTXGmuMAhbOjsP4OK1SD8neXN2ctSRG7ahMmO8lSXnfp5Sz-GjpuV7xHNecpt%7Ea7dEGAh1WtExg52JOunFZXxBT0UWpEVT40iqnkj1B1sMWXt2A841kUBLWk5Q5JHPvOyyGk5KNHEvnLNRdV6BPVFsRnsAZPKcKTFB9qfPS9C6gjuYqYp6UGSpGcGwygSCV0YTSAmcVYBQiwkD8lw__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n","--2024-06-24 06:10:35--  https://cdn-lfs.huggingface.co/datasets/huggingface/documentation-images/e037bbf4836b97f1034f3a16e144e5184e67058a5cc2dd4b2c966d916dfbfd1f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27conditioning_image_2.png%3B+filename%3D%22conditioning_image_2.png%22%3B&response-content-type=image%2Fpng&Expires=1719468635&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxOTQ2ODYzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9kYXRhc2V0cy9odWdnaW5nZmFjZS9kb2N1bWVudGF0aW9uLWltYWdlcy9lMDM3YmJmNDgzNmI5N2YxMDM0ZjNhMTZlMTQ0ZTUxODRlNjcwNThhNWNjMmRkNGIyYzk2NmQ5MTZkZmJmZDFmP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&Signature=bHQ0NreHamLgRvujtOpu4XSW3AawxBFRddxPM3n01p2txBTV7Bs3wPhTes1lcbPFznD78teW%7E0pjPmJFdhKqiL5BxtFBtwqfXKUDZtm9aTKpZ11%7Egzz7-IN09uDwLj%7EyiUUYdcTXGmuMAhbOjsP4OK1SD8neXN2ctSRG7ahMmO8lSXnfp5Sz-GjpuV7xHNecpt%7Ea7dEGAh1WtExg52JOunFZXxBT0UWpEVT40iqnkj1B1sMWXt2A841kUBLWk5Q5JHPvOyyGk5KNHEvnLNRdV6BPVFsRnsAZPKcKTFB9qfPS9C6gjuYqYp6UGSpGcGwygSCV0YTSAmcVYBQiwkD8lw__&Key-Pair-Id=K3ESJI6DHPFC7\n","Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.185.94, 18.154.185.26, 18.154.185.64, ...\n","Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.185.94|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 7218 (7.0K) [image/png]\n","Saving to: ‘conditioning_image_2.png’\n","\n","conditioning_image_ 100%[===================>]   7.05K  --.-KB/s    in 0s      \n","\n","2024-06-24 06:10:35 (1.53 GB/s) - ‘conditioning_image_2.png’ saved [7218/7218]\n","\n"]}]},{"cell_type":"code","source":["mkdir output_path"],"metadata":{"id":"Y2Pf3ic-8f4W","executionInfo":{"status":"ok","timestamp":1719210751176,"user_tz":-330,"elapsed":440,"user":{"displayName":"chaturya ganne","userId":"10364823250779832102"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["import os\n","os.environ['MODEL_DIR'] = 'runwayml/stable-diffusion-v1-5'\n","os.environ['OUTPUT_DIR'] = '/content/diffusers/examples/controlnet/output_path'\n","\n","\n","\n","# Run the training script with accelerate\n","!accelerate launch diffusers/examples/controlnet/train_controlnet.py \\\n"," --pretrained_model_name_or_path=$MODEL_DIR \\\n"," --output_dir=$OUTPUT_DIR \\\n"," --dataset_name=fusing/fill50k \\\n"," --resolution=512 \\\n"," --learning_rate=1e-5 \\\n"," --validation_image \"./conditioning_image_1.png\" \"./conditioning_image_2.png\" \\\n"," --validation_prompt \"red circle with blue background\" \"cyan circle with brown floral background\" \\\n"," --train_batch_size=4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gKY1kUYr7nKx","executionInfo":{"status":"ok","timestamp":1719210942870,"user_tz":-330,"elapsed":10414,"user":{"displayName":"chaturya ganne","userId":"10364823250779832102"}},"outputId":"a65d2b83-a135-48ea-d412-059601357ca4"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/bin/python3: can't open file '/content/diffusers/examples/controlnet/diffusers/examples/controlnet/train_controlnet.py': [Errno 2] No such file or directory\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/accelerate\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n","    args.func(args)\n","  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 1097, in launch_command\n","    simple_launcher(args)\n","  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 703, in simple_launcher\n","    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n","subprocess.CalledProcessError: Command '['/usr/bin/python3', 'diffusers/examples/controlnet/train_controlnet.py', '--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5', '--output_dir=/content/diffusers/examples/controlnet/output_path', '--dataset_name=fusing/fill50k', '--resolution=512', '--learning_rate=1e-5', '--validation_image', './conditioning_image_1.png', './conditioning_image_2.png', '--validation_prompt', 'red circle with blue background', 'cyan circle with brown floral background', '--train_batch_size=4']' returned non-zero exit status 2.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"D_4cXU9j7nXE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mkdir savec\n"],"metadata":{"id":"pjIijoJQgltW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n","from diffusers.utils import load_image\n","import torch\n","\n","base_model_path = \"unwayml/stable-diffusion-v1-5\"\n","controlnet_path = \"/content/output_model\"\n","\n","controlnet = ControlNetModel.from_pretrained(controlnet_path, torch_dtype=torch.float16)\n","pipe = StableDiffusionControlNetPipeline.from_pretrained(\n","    base_model_path, controlnet=controlnet, torch_dtype=torch.float16\n",")\n","\n","# speed up diffusion process with faster scheduler and memory optimization\n","pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n","# remove following line if xformers is not installed or when using Torch 2.0.\n","pipe.enable_xformers_memory_efficient_attention()\n","# memory optimization.\n","pipe.enable_model_cpu_offload()\n","\n","control_image = load_image(\"./conditioning_image_1.png\")\n","prompt = \"pale golden rod circle with old lace background\"\n","\n","# generate image\n","generator = torch.manual_seed(0)\n","image = pipe(\n","    prompt, num_inference_steps=20, generator=generator, image=control_image\n",").images[0]\n","image.save(\"./output.png\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460},"id":"N7S-o1IYdzJn","executionInfo":{"status":"error","timestamp":1719203809037,"user_tz":-330,"elapsed":628,"user":{"displayName":"chaturya ganne","userId":"10364823250779832102"}},"outputId":"2478607b-d781-4f1a-cd27-48ba1b5a71ff"},"execution_count":null,"outputs":[{"output_type":"error","ename":"OSError","evalue":"Error no file named config.json found in directory /content/output_model.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-ce61958de2e7>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcontrolnet_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/output_model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcontrolnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mControlNetModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrolnet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m pipe = StableDiffusionControlNetPipeline.from_pretrained(\n\u001b[1;32m     10\u001b[0m     \u001b[0mbase_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrolnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontrolnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/diffusers/src/diffusers/models/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;31m# load config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         config, unused_kwargs, commit_hash = cls.load_config(\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/diffusers/src/diffusers/configuration_utils.py\u001b[0m in \u001b[0;36mload_config\u001b[0;34m(cls, pretrained_model_name_or_path, return_unused_kwargs, return_commit_hash, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0mconfig_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 raise EnvironmentError(\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0;34mf\"Error no file named {cls.config_name} found in directory {pretrained_model_name_or_path}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 )\n","\u001b[0;31mOSError\u001b[0m: Error no file named config.json found in directory /content/output_model."]}]},{"cell_type":"code","source":[],"metadata":{"id":"CMilNtQjdzMd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2MFHxmXGdzPJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"85uhdsl0dzSc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qDN9btWqdzV_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VwnhZPCPXhId"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gojXaSn7XhL_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11821,"status":"ok","timestamp":1719146778178,"user":{"displayName":"chaturya ganne","userId":"10364823250779832102"},"user_tz":-330},"id":"pO2UXzMrGd6N","outputId":"1638028a-09b4-48ad-e463-56602672b31f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'ControlNet'...\n","remote: Enumerating objects: 1356, done.\u001b[K\n","remote: Total 1356 (delta 0), reused 0 (delta 0), pack-reused 1356\u001b[K\n","Receiving objects: 100% (1356/1356), 122.40 MiB | 14.02 MiB/s, done.\n","Resolving deltas: 100% (599/599), done.\n"]}],"source":["!git clone https://github.com/lllyasviel/ControlNet.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dwsApyy3dEY4"},"outputs":[],"source":["#give the openpose as the input image and check\n","#do not give any prompt and see\n","#check different ways to change the controlnet\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":118944,"status":"ok","timestamp":1719146987416,"user":{"displayName":"chaturya ganne","userId":"10364823250779832102"},"user_tz":-330},"id":"7uKMOIAMdEbZ","outputId":"529c2d8a-c1ca-425d-a204-a27812e0e966"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [0/1000], Loss: 1.0032\n","Epoch [100/1000], Loss: 1.0013\n","Epoch [200/1000], Loss: 0.9966\n","Epoch [300/1000], Loss: 1.0008\n","Epoch [400/1000], Loss: 0.9961\n","Epoch [500/1000], Loss: 1.0008\n","Epoch [600/1000], Loss: 0.9973\n","Epoch [700/1000], Loss: 0.9993\n","Epoch [800/1000], Loss: 0.9998\n","Epoch [900/1000], Loss: 1.0044\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","class ControlNet(nn.Module):\n","    def __init__(self, input_dim, control_dim, hidden_dim):\n","        super(ControlNet, self).__init__()\n","        self.fc1 = nn.Linear(input_dim + control_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n","        self.fc3 = nn.Linear(hidden_dim, input_dim)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x, control):\n","        x = torch.cat((x, control), dim=-1)\n","        x = self.relu(self.fc1(x))\n","        x = self.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","class StableDiffusionModel(nn.Module):\n","    def __init__(self, image_size, noise_dim, control_dim, hidden_dim):\n","        super(StableDiffusionModel, self).__init__()\n","        self.image_size = image_size\n","        self.noise_dim = noise_dim\n","        self.control_dim = control_dim\n","        self.hidden_dim = hidden_dim\n","\n","        self.control_net = ControlNet(noise_dim, control_dim, hidden_dim)\n","\n","        self.fc1 = nn.Linear(noise_dim, 256)\n","        self.fc2 = nn.Linear(256, 512)\n","        self.fc3 = nn.Linear(512, image_size * image_size * 3)\n","\n","        self.relu = nn.ReLU()\n","        self.tanh = nn.Tanh()\n","\n","    def forward(self, noise, control):\n","        noise = self.control_net(noise, control)\n","        x = self.relu(self.fc1(noise))\n","        x = self.relu(self.fc2(x))\n","        x = self.tanh(self.fc3(x))\n","        x = x.view(-1, 3, self.image_size, self.image_size)\n","        return x\n","\n","# Hyperparameters\n","image_size = 64\n","noise_dim = 100\n","control_dim = 10\n","hidden_dim = 256\n","batch_size = 32\n","learning_rate = 0.0002\n","\n","# Initialize model, loss function, and optimizer\n","model = StableDiffusionModel(image_size, noise_dim, control_dim, hidden_dim)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Example training loop\n","num_epochs = 1000\n","for epoch in range(num_epochs):\n","    noise = torch.randn(batch_size, noise_dim)\n","    control = torch.randn(batch_size, control_dim)\n","    fake_images = model(noise, control)\n","\n","    # Assume target_images is a batch of real images\n","    target_images = torch.randn(batch_size, 3, image_size, image_size)\n","\n","    loss = criterion(fake_images, target_images)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 100 == 0:\n","        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":512},"executionInfo":{"elapsed":951140,"status":"error","timestamp":1719148519266,"user":{"displayName":"chaturya ganne","userId":"10364823250779832102"},"user_tz":-330},"id":"BTbfIAibdEeA","outputId":"a020c684-ac01-48a5-90cf-bfd9afa1ced5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [0/1000], Loss: 1.0000\n","Epoch [100/1000], Loss: 1.0028\n","Epoch [200/1000], Loss: 1.0032\n","Epoch [300/1000], Loss: 1.0006\n","Epoch [400/1000], Loss: 0.9965\n","Epoch [500/1000], Loss: 0.9970\n","Epoch [600/1000], Loss: 1.0022\n","Epoch [700/1000], Loss: 0.9969\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-965e4bc35053>\u001b[0m in \u001b[0;36m<cell line: 109>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                             )\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 state_steps)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    319\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;31m# Lastly, switch back to complex view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms\n","from transformers import BertModel, BertTokenizer\n","from PIL import Image\n","\n","class TextEncoder(nn.Module):\n","    def __init__(self, pretrained_model='bert-base-uncased'):\n","        super(TextEncoder, self).__init__()\n","        self.bert = BertModel.from_pretrained(pretrained_model)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids, attention_mask=attention_mask)\n","        return outputs.last_hidden_state[:, 0, :]  # CLS token\n","\n","class ImageEncoder(nn.Module):\n","    def __init__(self, input_channels=3, output_dim=512):\n","        super(ImageEncoder, self).__init__()\n","        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=4, stride=2, padding=1)\n","        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n","        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n","        self.conv4 = nn.Conv2d(256, output_dim, kernel_size=4, stride=2, padding=1)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.relu(self.conv1(x))\n","        x = self.relu(self.conv2(x))\n","        x = self.relu(self.conv3(x))\n","        x = self.relu(self.conv4(x))\n","        x = x.view(x.size(0), -1)\n","        return x\n","\n","class ControlNet(nn.Module):\n","    def __init__(self, input_dim, control_dim, hidden_dim):\n","        super(ControlNet, self).__init__()\n","        self.fc1 = nn.Linear(input_dim + control_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n","        self.fc3 = nn.Linear(hidden_dim, input_dim)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x, control):\n","        x = torch.cat((x, control), dim=-1)\n","        x = self.relu(self.fc1(x))\n","        x = self.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","class StableDiffusionModel(nn.Module):\n","    def __init__(self, image_size, noise_dim, control_dim, hidden_dim):\n","        super(StableDiffusionModel, self).__init__()\n","        self.image_size = image_size\n","        self.noise_dim = noise_dim\n","        self.control_dim = control_dim\n","        self.hidden_dim = hidden_dim\n","\n","        self.control_net = ControlNet(noise_dim, control_dim, hidden_dim)\n","\n","        self.fc1 = nn.Linear(noise_dim, 256)\n","        self.fc2 = nn.Linear(256, 512)\n","        self.fc3 = nn.Linear(512, image_size * image_size * 3)\n","\n","        self.relu = nn.ReLU()\n","        self.tanh = nn.Tanh()\n","\n","    def forward(self, noise, control):\n","        noise = self.control_net(noise, control)\n","        x = self.relu(self.fc1(noise))\n","        x = self.relu(self.fc2(x))\n","        x = self.tanh(self.fc3(x))\n","        x = x.view(-1, 3, self.image_size, self.image_size)\n","        return x\n","\n","# Hyperparameters\n","image_size = 64\n","noise_dim = 100\n","text_dim = 768  # BERT base hidden size\n","image_feature_dim = image_size // 16 * image_size // 16 * 512  # Output dimension from ImageEncoder\n","control_dim = text_dim + image_feature_dim\n","hidden_dim = 512\n","batch_size = 32\n","learning_rate = 0.0002\n","\n","# Initialize models, tokenizer, loss function, and optimizer\n","text_encoder = TextEncoder()\n","image_encoder = ImageEncoder()\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = StableDiffusionModel(image_size, noise_dim, control_dim, hidden_dim)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(list(text_encoder.parameters()) + list(image_encoder.parameters()) + list(model.parameters()), lr=learning_rate)\n","\n","# Example text and image input\n","text_input = [\"A beautiful landscape with mountains and a river\"]\n","inputs = tokenizer(text_input, return_tensors=\"pt\", padding=True, truncation=True)\n","input_ids = inputs['input_ids']\n","attention_mask = inputs['attention_mask']\n","\n","# Load and preprocess input image\n","transform = transforms.Compose([\n","    transforms.Resize((image_size, image_size)),\n","    transforms.ToTensor()\n","])\n","\n","input_image = Image.open('person.png')  # Replace with your image path\n","input_image = transform(input_image).unsqueeze(0)\n","\n","# Example training loop\n","num_epochs = 1000\n","for epoch in range(num_epochs):\n","    noise = torch.randn(batch_size, noise_dim)\n","\n","    text_features = text_encoder(input_ids, attention_mask).repeat(batch_size, 1)  # Repeat for batch\n","    image_features = image_encoder(input_image).repeat(batch_size, 1)  # Repeat for batch\n","\n","    control = torch.cat((text_features, image_features), dim=-1)\n","\n","    fake_images = model(noise, control)\n","\n","    # Assume target_images is a batch of real images\n","    target_images = torch.randn(batch_size, 3, image_size, image_size)\n","\n","    loss = criterion(fake_images, target_images)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","        # Display generated image\n","\n","    if epoch % 100 == 0:\n","        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","        generated_image = fake_images[0].detach().cpu()\n","\n","        # Denormalize the image from [-1, 1] to [0, 1]\n","        generated_image = (generated_image + 1) / 2\n","\n","        # Convert to PIL Image\n","        generated_image = transforms.ToPILImage()(generated_image)\n","\n","        # Display the image\n","        plt.imshow(generated_image)\n","        plt.axis('off')\n","        plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EDgEmE9cNDe7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g3TsC5PndEgo"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms\n","from transformers import BertModel, BertTokenizer\n","from PIL import Image\n","\n","class TextEncoder(nn.Module):\n","    def __init__(self, pretrained_model='bert-base-uncased'):\n","        super(TextEncoder, self).__init__()\n","        self.bert = BertModel.from_pretrained(pretrained_model)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids, attention_mask=attention_mask)\n","        return outputs.last_hidden_state[:, 0, :]  # CLS token\n","\n","class ImageEncoder(nn.Module):\n","    def __init__(self, input_channels=3, output_dim=512):\n","        super(ImageEncoder, self).__init__()\n","        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=4, stride=2, padding=1)\n","        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n","        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n","        self.conv4 = nn.Conv2d(256, output_dim, kernel_size=4, stride=2, padding=1)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.relu(self.conv1(x))\n","        x = self.relu(self.conv2(x))\n","        x = self.relu(self.conv3(x))\n","        x = self.relu(self.conv4(x))\n","        x = x.view(x.size(0), -1)\n","        return x\n","\n","class ControlNet(nn.Module):\n","    def __init__(self, input_dim, control_dim, hidden_dim):\n","        super(ControlNet, self).__init__()\n","        self.fc1 = nn.Linear(input_dim + control_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n","        self.fc3 = nn.Linear(hidden_dim, input_dim)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x, control):\n","        x = torch.cat((x, control), dim=-1)\n","        x = self.relu(self.fc1(x))\n","        x = self.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","class StableDiffusionModel(nn.Module):\n","    def __init__(self, image_size, noise_dim, control_dim, hidden_dim):\n","        super(StableDiffusionModel, self).__init__()\n","        self.image_size = image_size\n","        self.noise_dim = noise_dim\n","        self.control_dim = control_dim\n","        self.hidden_dim = hidden_dim\n","\n","        self.control_net = ControlNet(noise_dim, control_dim, hidden_dim)\n","\n","        self.fc1 = nn.Linear(noise_dim, 256)\n","        self.fc2 = nn.Linear(256, 512)\n","        self.fc3 = nn.Linear(512, image_size * image_size * 3)\n","\n","        self.relu = nn.ReLU()\n","        self.tanh = nn.Tanh()\n","\n","    def forward(self, noise, control):\n","        noise = self.control_net(noise, control)\n","        x = self.relu(self.fc1(noise))\n","        x = self.relu(self.fc2(x))\n","        x = self.tanh(self.fc3(x))\n","        x = x.view(-1, 3, self.image_size, self.image_size)\n","        return x\n","\n","# Hyperparameters\n","image_size = 64\n","noise_dim = 100\n","text_dim = 768  # BERT base hidden size\n","image_feature_dim = image_size // 16 * image_size // 16 * 512  # Output dimension from ImageEncoder\n","control_dim = text_dim + image_feature_dim\n","hidden_dim = 512\n","batch_size = 1\n","learning_rate = 0.0002\n","\n","# Initialize models, tokenizer, loss function, and optimizer\n","text_encoder = TextEncoder()\n","image_encoder = ImageEncoder()\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = StableDiffusionModel(image_size, noise_dim, control_dim, hidden_dim)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(list(text_encoder.parameters()) + list(image_encoder.parameters()) + list(model.parameters()), lr=learning_rate)\n","\n","# Example text and image input\n","text_input = [\"A beautiful landscape with mountains and a river\"]\n","inputs = tokenizer(text_input, return_tensors=\"pt\", padding=True, truncation=True)\n","input_ids = inputs['input_ids']\n","attention_mask = inputs['attention_mask']\n","\n","# Load and preprocess input image\n","transform = transforms.Compose([\n","    transforms.Resize((image_size, image_size)),\n","    transforms.ToTensor()\n","])\n","\n","input_image = Image.open('person.png')\n","input_image = Image.resize((64,64))  # Replace with your image path\n","input_image = transform(input_image).unsqueeze(0)\n","\n","# Check dimensions\n","print(f\"Input image shape: {input_image.shape}\")  # Should be (1, 3, 64, 64)\n","\n","# Example training loop\n","num_epochs = 1000\n","for epoch in range(num_epochs):\n","    noise = torch.randn(batch_size, noise_dim)\n","\n","    text_features = text_encoder(input_ids, attention_mask).repeat(batch_size, 1)  # Repeat for batch\n","    image_features = image_encoder(input_image).repeat(batch_size, 1)  # Repeat for batch\n","\n","    print(f\"Text features shape: {text_features.shape}\")  # Should be (batch_size, 768)\n","    print(f\"Image features shape: {image_features.shape}\")  # Should be (batch_size, 8192)\n","\n","    control = torch.cat((text_features, image_features), dim=-1)\n","\n","    fake_images = model(noise, control)\n","\n","    # Assume target_images is a batch of real images\n","    target_images = torch.randn(batch_size, 3, image_size, image_size)\n","\n","    loss = criterion(fake_images, target_images)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 100 == 0:\n","        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":847},"id":"S0aKepe6dEkC","outputId":"90487d7e-0ed2-4474-95a0-2cf33ab357dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input image shape: torch.Size([1, 3, 64, 64])\n","Epoch [0/1000], Loss: 0.9921\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch [100/1000], Loss: 1.0177\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms\n","from transformers import BertModel, BertTokenizer\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","class TextEncoder(nn.Module):\n","    def __init__(self, pretrained_model='bert-base-uncased'):\n","        super(TextEncoder, self).__init__()\n","        self.bert = BertModel.from_pretrained(pretrained_model)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids, attention_mask=attention_mask)\n","        return outputs.last_hidden_state[:, 0, :]  # CLS token\n","\n","class ImageEncoder(nn.Module):\n","    def __init__(self, input_channels=3, output_dim=512):\n","        super(ImageEncoder, self).__init__()\n","        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=4, stride=2, padding=1)\n","        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n","        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n","        self.conv4 = nn.Conv2d(256, output_dim, kernel_size=4, stride=2, padding=1)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.relu(self.conv1(x))\n","        x = self.relu(self.conv2(x))\n","        x = self.relu(self.conv3(x))\n","        x = self.relu(self.conv4(x))\n","        x = x.view(x.size(0), -1)\n","        return x\n","\n","class ControlNet(nn.Module):\n","    def __init__(self, input_dim, control_dim, hidden_dim):\n","        super(ControlNet, self).__init__()\n","        self.fc1 = nn.Linear(input_dim + control_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n","        self.fc3 = nn.Linear(hidden_dim, input_dim)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x, control):\n","        x = torch.cat((x, control), dim=-1)\n","        x = self.relu(self.fc1(x))\n","        x = self.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","class StableDiffusionModel(nn.Module):\n","    def __init__(self, image_size, noise_dim, control_dim, hidden_dim):\n","        super(StableDiffusionModel, self).__init__()\n","        self.image_size = image_size\n","        self.noise_dim = noise_dim\n","        self.control_dim = control_dim\n","        self.hidden_dim = hidden_dim\n","\n","        self.control_net = ControlNet(noise_dim, control_dim, hidden_dim)\n","\n","        self.fc1 = nn.Linear(noise_dim, 256)\n","        self.fc2 = nn.Linear(256, 512)\n","        self.fc3 = nn.Linear(512, image_size * image_size * 3)\n","\n","        self.relu = nn.ReLU()\n","        self.tanh = nn.Tanh()\n","\n","    def forward(self, noise, control):\n","        noise = self.control_net(noise, control)\n","        x = self.relu(self.fc1(noise))\n","        x = self.relu(self.fc2(x))\n","        x = self.tanh(self.fc3(x))\n","        x = x.view(-1, 3, self.image_size, self.image_size)\n","        return x\n","\n","# Hyperparameters\n","image_size = 64\n","noise_dim = 100\n","text_dim = 768  # BERT base hidden size\n","image_feature_dim = image_size // 16 * image_size // 16 * 512  # Output dimension from ImageEncoder\n","control_dim = text_dim + image_feature_dim\n","hidden_dim = 512\n","batch_size = 1\n","learning_rate = 0.0002\n","\n","# Initialize models, tokenizer, loss function, and optimizer\n","text_encoder = TextEncoder()\n","image_encoder = ImageEncoder()\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = StableDiffusionModel(image_size, noise_dim, control_dim, hidden_dim)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(list(text_encoder.parameters()) + list(image_encoder.parameters()) + list(model.parameters()), lr=learning_rate)\n","\n","# Example text and image input\n","text_input = [\"A beautiful landscape with mountains and a river\"]\n","inputs = tokenizer(text_input, return_tensors=\"pt\", padding=True, truncation=True)\n","input_ids = inputs['input_ids']\n","attention_mask = inputs['attention_mask']\n","\n","# Load and preprocess input image\n","transform = transforms.Compose([\n","    transforms.Resize((image_size, image_size)),\n","    transforms.ToTensor()\n","])\n","\n","input_image = Image.open('person.png')\n","#input_image = input_image.resize((64,64)) # Replace with your image path\n","input_image = transform(input_image).unsqueeze(0)\n","\n","# Check dimensions\n","print(f\"Input image shape: {input_image.shape}\")  # Should be (1, 3, 64, 64)\n","\n","# Example training loop\n","num_epochs = 1000\n","for epoch in range(num_epochs):\n","    noise = torch.randn(batch_size, noise_dim)\n","\n","    text_features = text_encoder(input_ids, attention_mask).repeat(batch_size, 1)  # Repeat for batch\n","    image_features = image_encoder(input_image).repeat(batch_size, 1)  # Repeat for batch\n","\n","    #print(f\"Text features shape: {text_features.shape}\")  # Should be (batch_size, 768)\n","    #print(f\"Image features shape: {image_features.shape}\")  # Should be (batch_size, 8192)\n","\n","    control = torch.cat((text_features, image_features), dim=-1)\n","\n","    fake_images = model(noise, control)\n","\n","    # Assume target_images is a batch of real images\n","    target_images = torch.randn(batch_size, 3, image_size, image_size)\n","\n","    loss = criterion(fake_images, target_images)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 100 == 0:\n","        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","        # Display generated image\n","        generated_image = fake_images[0].detach().cpu()\n","\n","        # Denormalize the image from [-1, 1] to [0, 1]\n","        generated_image = (generated_image + 1) / 2\n","\n","        # Convert to PIL Image\n","        generated_image = transforms.ToPILImage()(generated_image)\n","\n","        # Display the image\n","        plt.imshow(generated_image)\n","        plt.axis('off')\n","        plt.show()\n"]},{"cell_type":"code","source":["from transformers import BertModel\n","\n","model = BertModel.from_pretrained(\"bert-base-uncased\", torch_dtype=torch.float16, attn_implementation=\"sdpa\")"],"metadata":{"id":"5qPA7BGLPyr7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class UNet(nn.Module):\n","    def __init__(self, in_channels=3, out_channels=3, init_features=32):\n","        super(UNet, self).__init__()\n","\n","        features = init_features\n","        self.encoder1 = UNet._block(in_channels, features)\n","        self.encoder2 = UNet._block(features, features * 2)\n","        self.encoder3 = UNet._block(features * 2, features * 4)\n","        self.encoder4 = UNet._block(features * 4, features * 8)\n","\n","        self.bottleneck = UNet._block(features * 8, features * 16)\n","\n","        self.decoder4 = UNet._block(features * 16, features * 8)\n","        self.decoder3 = UNet._block(features * 8, features * 4)\n","        self.decoder2 = UNet._block(features * 4, features * 2)\n","        self.decoder1 = UNet._block(features * 2, features)\n","\n","        self.final_layer = nn.Conv2d(features, out_channels, kernel_size=1)\n","\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.upconv4 = nn.ConvTranspose2d(features * 16, features * 8, kernel_size=2, stride=2)\n","        self.upconv3 = nn.ConvTranspose2d(features * 8, features * 4, kernel_size=2, stride=2)\n","        self.upconv2 = nn.ConvTranspose2d(features * 4, features * 2, kernel_size=2, stride=2)\n","        self.upconv1 = nn.ConvTranspose2d(features * 2, features, kernel_size=2, stride=2)\n","\n","    def forward(self, x):\n","        enc1 = self.encoder1(x)\n","        enc2 = self.encoder2(self.pool(enc1))\n","        enc3 = self.encoder3(self.pool(enc2))\n","        enc4 = self.encoder4(self.pool(enc3))\n","\n","        bottleneck = self.bottleneck(self.pool(enc4))\n","\n","        dec4 = self.upconv4(bottleneck)\n","        dec4 = torch.cat((dec4, enc4), dim=1)\n","        dec4 = self.decoder4(dec4)\n","\n","        dec3 = self.upconv3(dec4)\n","        dec3 = torch.cat((dec3, enc3), dim=1)\n","        dec3 = self.decoder3(dec3)\n","\n","        dec2 = self.upconv2(dec3)\n","        dec2 = torch.cat((dec2, enc2), dim=1)\n","        dec2 = self.decoder2(dec2)\n","\n","        dec1 = self.upconv1(dec2)\n","        dec1 = torch.cat((dec1, enc1), dim=1)\n","        dec1 = self.decoder1(dec1)\n","\n","        return torch.tanh(self.final_layer(dec1))\n","\n","    @staticmethod\n","    def _block(in_channels, features, name=\"\"):\n","        return nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels, out_channels=features, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(num_features=features),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels=features, out_channels=features, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(num_features=features),\n","            nn.ReLU(inplace=True)\n","        )\n"],"metadata":{"id":"qN-wb9vIPTqy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class StableDiffusionModel(nn.Module):\n","    def __init__(self, image_size, noise_dim, control_dim, hidden_dim):\n","        super(StableDiffusionModel, self).__init__()\n","        self.image_size = image_size\n","        self.noise_dim = noise_dim\n","        self.control_dim = control_dim\n","        self.hidden_dim = hidden_dim\n","\n","        self.control_net = ControlNet(noise_dim, control_dim, hidden_dim)\n","\n","        self.unet = UNet(in_channels=3, out_channels=3)\n","\n","    def forward(self, noise, control):\n","        # Combine noise and control vectors using ControlNet\n","        noise = self.control_net(noise, control)\n","\n","        # Reshape noise to image size\n","        noise = noise.view(-1, 3, self.image_size, self.image_size)\n","\n","        # Pass through the UNet for denoising\n","        denoised_image = self.unet(noise)\n","\n","        return denoised_image\n"],"metadata":{"id":"vflDNfDNPTt8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hyperparameters\n","image_size = 64\n","noise_dim = 100\n","text_dim = 768  # BERT base hidden size\n","image_feature_dim = image_size // 16 * image_size // 16 * 512  # Output dimension from ImageEncoder\n","control_dim = text_dim + image_feature_dim\n","hidden_dim = 512\n","batch_size = 1\n","learning_rate = 0.0002\n","\n","# Initialize models, tokenizer, loss function, and optimizer\n","text_encoder = TextEncoder()\n","image_encoder = ImageEncoder()\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = StableDiffusionModel(image_size, noise_dim, control_dim, hidden_dim)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(list(text_encoder.parameters()) + list(image_encoder.parameters()) + list(model.parameters()), lr=learning_rate)\n","\n","# Example text and image input\n","text_input = [\"A beautiful landscape with mountains and a river\"]\n","inputs = tokenizer(text_input, return_tensors=\"pt\", padding=True, truncation=True)\n","input_ids = inputs['input_ids']\n","attention_mask = inputs['attention_mask']\n","\n","# Load and preprocess input image\n","transform = transforms.Compose([\n","    transforms.Resize((image_size, image_size)),\n","    transforms.ToTensor()\n","])\n","\n","input_image = Image.open('person.png')\n","input_image = transform(input_image).unsqueeze(0)\n","\n","# Check dimensions\n","print(f\"Input image shape: {input_image.shape}\")  # Should be (1, 3, 64, 64)\n","\n","# Example training loop\n","num_epochs = 1000\n","for epoch in range(num_epochs):\n","    noise = torch.randn(batch_size, noise_dim)\n","\n","    text_features = text_encoder(input_ids, attention_mask).repeat(batch_size, 1)  # Repeat for batch\n","    image_features = image_encoder(input_image).repeat(batch_size, 1)  # Repeat for batch\n","\n","    control = torch.cat((text_features, image_features), dim=-1)\n","\n","    fake_images = model(noise, control)\n","\n","    # Assume target_images is a batch of real images\n","    target_images = torch.randn(batch_size, 3, image_size, image_size)\n","\n","    loss = criterion(fake_images, target_images)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 100 == 0:\n","        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","        # Display generated image\n","        generated_image = fake_images[0].detach().cpu()\n","\n","        # Denormalize the image from [-1, 1] to [0, 1]\n","        generated_image = (generated_image + 1) / 2\n","\n","        # Convert to PIL Image\n","        generated_image = transforms.ToPILImage()(generated_image)\n","\n","        # Display the image\n","        plt.imshow(generated_image)\n","        plt.axis('off')\n","        plt.show()\n"],"metadata":{"id":"COMi741YPTxg"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyNf1qIoae/wu1hPtac0w1aX"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}